{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backgrounf_sub():\n",
    "    fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while(1):\n",
    "        ret, frame = cap.read()\n",
    "        fgmask = fgbg.apply(frame)\n",
    "        cv2.imshow('frame',fgmask)\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Color Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mySkinDetect(src):\n",
    "    # Surveys of skin color modeling and detection techniques:\n",
    "    # 1. Vezhnevets, Vladimir, Vassili Sazonov, and Alla Andreeva. \"A survey on pixel-based skin color detection techniques.\" Proc. Graphicon. Vol. 3. 2003.\n",
    "    # 2. Kakumanu, Praveen, Sokratis Makrogiannis, and Nikolaos Bourbakis. \"A survey of skin-color modeling and detection methods.\" Pattern recognition 40.3 (2007): 1106-1122.\n",
    "    dst = np.zeros((src.shape[0], src.shape[1], 1), dtype = \"uint8\")\n",
    "    for i in range(src.shape[0]):\n",
    "        for j in range(src.shape[1]):\n",
    "            #b,g,r = src[i,j]\n",
    "            b = int(src[i,j][0])\n",
    "            g = int(src[i,j][1])\n",
    "            r = int(src[i,j][2])\n",
    "            if(r>95 and g>40 and b>20 and max(r,g,b)-min(r,g,b)>15 and abs(r-g)>15 and r>g and r>b):\n",
    "                dst[i,j] = 255\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# frame-to-frame differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myFrameDifferencing(prev, curr):\n",
    "    # For more information on operation with arrays: \n",
    "    # http://docs.opencv.org/modules/core/doc/operations_on_arrays.html\n",
    "    \n",
    "    # code here...\n",
    "    dst = cv2.absdiff(curr, prev)\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "    _, dst = cv2.threshold(dst, 50, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myMotionEnergy(mh):\n",
    "    # the window of time is 3\n",
    "    mh0 = mh[0]\n",
    "    mh1 = mh[1]\n",
    "    mh2 = mh[2]\n",
    "    dst = np.zeros((mh0.shape[0], mh0.shape[1], 1), dtype = \"uint8\")\n",
    "    \n",
    "    # code here...\n",
    "    for i in range(dst.shape[0]):\n",
    "        for j in range(dst.shape[1]):\n",
    "            if mh0[i, j] ==  255 or mh1[i, j] == 255 or mh2[i, j] == 255:\n",
    "                dst[i, j] = 255\n",
    "    \n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_match(img):\n",
    "    img2 = img.copy()\n",
    "    template = cv2.imread('fist.png',0)\n",
    "    w, h = template.shape[::-1]\n",
    "\n",
    "    # All the 6 methods for comparison in a list\n",
    "    methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n",
    "                'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "\n",
    "    for meth in methods:\n",
    "        img = img2.copy()\n",
    "        method = eval(meth)\n",
    "\n",
    "        # Apply template Matching\n",
    "        res = cv2.matchTemplate(img,template,method)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "        # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "        if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "            top_left = min_loc\n",
    "        else:\n",
    "            top_left = max_loc\n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "\n",
    "        cv2.rectangle(img,top_left, bottom_right, 255, 2)\n",
    "\n",
    "        plt.subplot(121),plt.imshow(res,cmap = 'gray')\n",
    "        plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
    "        plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "        plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
    "        plt.suptitle(meth)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # a) Reading a stream of images from a webcamera, and displaying the video\n",
    "    # open the video camera no. 0\n",
    "    # for more information on reading and writing video: http://docs.opencv.org/modules/highgui/doc/reading_and_writing_images_and_video.html\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    #if not successful, exit program\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open the video cam\")\n",
    "        return -1\n",
    "\n",
    "    # read a new frame from video\n",
    "    success, prev_frame = cap.read()\n",
    "    \n",
    "    #if not successful, exit program\n",
    "    if not success:\n",
    "        print(\"Cannot read a frame from video stream\")\n",
    "        return -1\n",
    "    cv2.namedWindow(\"frame\", cv2.WINDOW_AUTOSIZE)\n",
    "    \n",
    "    prev_frame = cv2.resize(prev_frame,(150,150))\n",
    "    fMH1 = np.zeros((prev_frame.shape[0], prev_frame.shape[1], 1), dtype = \"uint8\")\n",
    "    fMH2 = fMH1.copy()\n",
    "    fMH3 = fMH1.copy()\n",
    "    myMotionHistory = deque([fMH1, fMH2, fMH3]) \n",
    "    while(True):\n",
    "        #read a new frame from video\n",
    "        success, curr_frame = cap.read()\n",
    "        curr_frame = cv2.resize(curr_frame,(150,150))\n",
    "        if not success:\n",
    "            print(\"Cannot read a frame from video stream\")\n",
    "            break\n",
    "    \n",
    "        #cv2.imshow('frame',curr_frame)\n",
    "\n",
    "        # b) Skin color detection\n",
    "        mySkin = mySkinDetect(curr_frame)\n",
    "        #cv2.imshow('mySkinDetect',mySkin)\n",
    "\n",
    "        # c) Background differencing\n",
    "        frameDest = myFrameDifferencing(prev_frame, curr_frame)\n",
    "        #cv2.imshow('myFrameDifferencing',frameDest)\n",
    "\n",
    "        # d) Visualizing motion history\n",
    "        myMotionHistory.popleft()\n",
    "        myMotionHistory.append(frameDest)\n",
    "        myMH = myMotionEnergy(myMotionHistory)\n",
    "        #cv2.imshow('myMotionHistory',myMH)\n",
    "        \n",
    "        # e) template matching\n",
    "        matching = template_match(curr_frame)\n",
    "        cv2.imshow('matching', matching)\n",
    "        \n",
    "        prev_frame = curr_frame\n",
    "        \n",
    "        \n",
    "        # wait for 'q' key press. If 'q' key is pressed, break loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.0) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/templmatch.cpp:1107: error: (-215:Assertion failed) (depth == CV_8U || depth == CV_32F) && type == _templ.type() && _img.dims() <= 2 in function 'matchTemplate'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-972361fa1b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-2cb217dd94cd>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# e) template matching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mmatching\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemplate_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matching'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatching\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-650dc7963699>\u001b[0m in \u001b[0;36mtemplate_match\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Apply template Matching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatchTemplate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mmin_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminMaxLoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.0.0) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/templmatch.cpp:1107: error: (-215:Assertion failed) (depth == CV_8U || depth == CV_32F) && type == _templ.type() && _img.dims() <= 2 in function 'matchTemplate'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
